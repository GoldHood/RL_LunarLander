{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b315f01-1ee3-4ebd-935d-179a993cefe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0+cu124\n",
      "Uninstalling torch-2.6.0+cu124:\n",
      "  Successfully uninstalled torch-2.6.0+cu124\n",
      "Found existing installation: torchvision 0.21.0+cu124\n",
      "Uninstalling torchvision-0.21.0+cu124:\n",
      "  Successfully uninstalled torchvision-0.21.0+cu124\n",
      "Found existing installation: torchaudio 2.6.0+cu124\n",
      "Uninstalling torchaudio-2.6.0+cu124:\n",
      "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5619dfc-8c76-4841-8f7f-b4c669c30c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping box2d-py as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping box2d as it is not installed.\u001b[0m\u001b[33m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y box2d-py Box2D box2d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab0ecc46-f94a-474f-9e7e-03a3cb6413a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Preferido (tiene wheels para py3.12):\n",
    "%pip install --no-cache-dir -q --only-binary=:all: Box2D==2.3.10\n",
    "\n",
    "# Si (y solo si) lo anterior fallara:\n",
    "# %pip install --no-cache-dir -q --only-binary=:all: box2d-py==2.3.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915fdff5-8153-4741-8170-41b3126fbeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# CPU seguro\n",
    "%pip install -q --index-url https://download.pytorch.org/whl/cpu torch==2.5.1+cpu\n",
    "# (o cu121 si estás 100% seguro que tu entorno tiene CUDA 12.1 funcional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb55dd65-d60e-4264-ba34-05e05e84b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q numpy==1.26.4 matplotlib==3.8.4 tqdm==4.66.4 cma==3.2.2 imageio==2.36.0 imageio-ffmpeg==0.5.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51afa40e-0189-46e8-afe7-bc8ebc0cbf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --no-cache-dir -q pygame==2.6.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474170c3-a57e-4fea-88d7-cccaadd74a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: box2d==2.3.10 in /opt/conda/lib/python3.12/site-packages (2.3.10)\n",
      "Collecting gymnasium==0.29.1\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pygame==2.6.1 in /opt/conda/lib/python3.12/site-packages (2.6.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /opt/conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib==3.8.4 in /opt/conda/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: tqdm==4.66.4 in /opt/conda/lib/python3.12/site-packages (4.66.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from gymnasium==0.29.1) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.12/site-packages (from gymnasium==0.29.1) (4.12.2)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium==0.29.1)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.4) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.4) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.4) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.4) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.4) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.4) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.8.4) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.8.4) (1.17.0)\n",
      "Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
     ]
    }
   ],
   "source": [
    "!pip install box2d==2.3.10 gymnasium==0.29.1 pygame==2.6.1 numpy==1.26.4 matplotlib==3.8.4 tqdm==4.66.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98578999-7ff0-41c7-9e9b-5205de2d7506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gym: 0.29.1 | Torch: 2.5.1+cpu\n",
      "Obs: (8,) Actions: 4\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym, Box2D, torch, numpy as np\n",
    "print(\"Gym:\", gym.__version__, \"| Torch:\", torch.__version__)\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "s, _ = env.reset()\n",
    "print(\"Obs:\", s.shape, \"Actions:\", env.action_space.n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a6e4e33-6b2a-4ced-87e6-b2b7f4249d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando: LunarLander-v2\n",
      "Estructura lista: [PosixPath('world_models/figs'), PosixPath('world_models/data'), PosixPath('world_models/videos'), PosixPath('world_models/checkpoints')]\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# 1) Carpeta del proyecto + semillas + utils\n",
    "# ===========================================\n",
    "from pathlib import Path\n",
    "import json, math, random, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "# --- Carpeta donde guardaremos TODO (dataset, modelos, videos, figuras)\n",
    "ROOT = Path(\"./world_models\")\n",
    "for p in [ROOT, ROOT/\"data\", ROOT/\"checkpoints\", ROOT/\"videos\", ROOT/\"figs\"]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Semillas para reproducibilidad\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# --- Elegimos la versión del entorno disponible\n",
    "def pick_lander_env():\n",
    "    for env_id in (\"LunarLander-v3\",\"LunarLander-v2\"):\n",
    "        try:\n",
    "            env = gym.make(env_id); env.close()\n",
    "            return env_id\n",
    "        except:\n",
    "            pass\n",
    "    raise RuntimeError(\"No encontré LunarLander v2/v3.\")\n",
    "ENV_ID = pick_lander_env()\n",
    "print(\"Usando:\", ENV_ID)\n",
    "\n",
    "# --- Rango “seguro” para recortar observaciones (ayuda a estabilizar el modelo)\n",
    "LOW  = np.array([-1.5,-0.5,-2.0,-2.0,-math.pi,-3.0,0.0,0.0],dtype=np.float32)\n",
    "HIGH = np.array([ 1.5, 1.5, 2.0, 2.0, math.pi, 3.0,1.0,1.0],dtype=np.float32)\n",
    "def clip_obs(s: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Recorta la observación a rangos razonables y asegura dtype float32.\"\"\"\n",
    "    s = np.asarray(s, np.float32)\n",
    "    s[:6] = np.clip(s[:6], LOW[:6], HIGH[:6])  # las 6 primeras son continuas\n",
    "    s[6:] = np.clip(s[6:], 0.0, 1.0)           # patas ya están en [0,1]\n",
    "    return s\n",
    "\n",
    "# --- Tupla para transiciones (s, a, r, s', done)\n",
    "Transition = namedtuple(\"Transition\", [\"s\",\"a\",\"r\",\"sp\",\"d\"])\n",
    "\n",
    "# --- Buffer simple (lo usaremos para recolectar dataset real)\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, cap=1_000_000): self.buf = deque(maxlen=cap)\n",
    "    def __len__(self): return len(self.buf)\n",
    "    def add(self, *args): self.buf.append(Transition(*args))\n",
    "\n",
    "print(\"Estructura lista:\", list(ROOT.iterdir()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00205794-7a8f-4b07-a4b6-dfde5f0ce8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recolectando: 2400000it [01:40, 23837.69it/s]                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset guardado en: /home/jovyan/MVP_RL_LunarLander/world_models/data/lander_dataset.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 2) Recolecta un dataset real con vecenv (rápido y estable)\n",
    "# ==========================================================\n",
    "from tqdm import trange\n",
    "\n",
    "def collect_dataset(env_id=ENV_ID, steps=300_000, num_envs=8,\n",
    "                    eps_start=1.0, eps_end=0.05):\n",
    "    \"\"\"\n",
    "    Recolecta 'steps' transiciones usando ε-greedy MUY simple.\n",
    "    - num_envs: entornos en paralelo (acelera muchísimo la recolección)\n",
    "    - epsilon: parte alto y decae linealmente; así mezclamos aleatorio y heurística\n",
    "    Guarda S, A, R, Sp, D + estadísticas para normalizar.\n",
    "    \"\"\"\n",
    "    env = gym.vector.make(env_id, num_envs=num_envs, asynchronous=True)\n",
    "    s, _ = env.reset(seed=SEED)\n",
    "    s = np.stack([clip_obs(si) for si in s])\n",
    "\n",
    "    S, A, R, Sp, D = [], [], [], [], []\n",
    "    eps = eps_start\n",
    "    pbar = trange(0, steps, num_envs, ncols=120, desc=\"Recolectando\")\n",
    "    while len(S) < steps:\n",
    "        # Política “tonta”: mira la altura y decide algo grosero sobre el motor\n",
    "        greedy = np.zeros((num_envs,), dtype=np.int64)\n",
    "        greedy[s[:,1] > 0.3] = 2  # (heurística arbitraria sólo para explorar)\n",
    "        greedy[s[:,1] < -0.3] = 1\n",
    "        a = greedy\n",
    "        # ε-greedy\n",
    "        mask = np.random.rand(num_envs) < eps\n",
    "        a[mask] = np.random.randint(0, 4, size=mask.sum())\n",
    "        # decaimos epsilon proporcional a transiciones\n",
    "        eps = max(eps_end, eps - (eps_start-eps_end) / (steps/num_envs))\n",
    "\n",
    "        sp, r, term, trunc, _ = env.step(a)\n",
    "        d = np.logical_or(term, trunc)\n",
    "        sp = np.stack([clip_obs(si) for si in sp])\n",
    "\n",
    "        S.append(s.copy()); A.append(a.copy()); R.append(r.copy()); Sp.append(sp.copy()); D.append(d.astype(np.float32))\n",
    "        s = sp\n",
    "        pbar.update(num_envs)\n",
    "    env.close()\n",
    "\n",
    "    # Concatenamos y guardamos\n",
    "    S = np.concatenate(S, 0); A = np.concatenate(A, 0); R = np.concatenate(R, 0)\n",
    "    Sp = np.concatenate(Sp, 0); D = np.concatenate(D, 0)\n",
    "\n",
    "    np.savez_compressed(ROOT/\"data\"/\"lander_dataset.npz\", S=S, A=A, R=R, Sp=Sp, D=D)\n",
    "    print(\"Dataset guardado en:\", (ROOT/\"data\"/\"lander_dataset.npz\").resolve())\n",
    "    return S, A, R, Sp, D\n",
    "\n",
    "# 🔁 Si es la primera vez, descomenta:\n",
    "S, A, R, Sp, D = collect_dataset(steps=300_000, num_envs=8)\n",
    "# Si ya lo tienes guardado, puedes cargarlo así:\n",
    "# data = np.load(ROOT/\"data\"/\"lander_dataset.npz\")\n",
    "# S, A, R, Sp, D = data[\"S\"], data[\"A\"], data[\"R\"], data[\"Sp\"], data[\"D\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "857cdb9e-7ba7-4353-b3ec-8fb2ef492e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats guardadas: /home/jovyan/MVP_RL_LunarLander/world_models/data/stats.json\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# 3) Estadísticas para normalizar entradas y targets\n",
    "# ==================================================\n",
    "class Stats:\n",
    "    \"\"\"\n",
    "    Guardamos medias y desvíos para:\n",
    "    - s (estado),\n",
    "    - ds = s_{t+1} - s_t,\n",
    "    - r (recompensa).\n",
    "    Esto vuelve \"bien condicionado\" el entrenamiento del modelo del mundo.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mu_s=None; self.std_s=None\n",
    "        self.mu_ds=None; self.std_ds=None\n",
    "        self.mu_r=0.;   self.std_r=1.\n",
    "    def fit(self, S, R, Sp):\n",
    "        DS = Sp - S\n",
    "        eps = 1e-6\n",
    "        self.mu_s  = S.mean(0); self.std_s  = S.std(0) + eps\n",
    "        self.mu_ds = DS.mean(0); self.std_ds = DS.std(0) + eps\n",
    "        self.mu_r  = float(R.mean()); self.std_r = float(R.std() + eps)\n",
    "    def dumps(self):\n",
    "        return dict(mu_s=self.mu_s.tolist(), std_s=self.std_s.tolist(),\n",
    "                    mu_ds=self.mu_ds.tolist(), std_ds=self.std_ds.tolist(),\n",
    "                    mu_r=self.mu_r, std_r=self.std_r)\n",
    "    @staticmethod\n",
    "    def loads(js):\n",
    "        st = Stats()\n",
    "        st.mu_s  = np.array(js[\"mu_s\"],  np.float32)\n",
    "        st.std_s = np.array(js[\"std_s\"], np.float32)\n",
    "        st.mu_ds = np.array(js[\"mu_ds\"], np.float32)\n",
    "        st.std_ds= np.array(js[\"std_ds\"],np.float32)\n",
    "        st.mu_r  = float(js[\"mu_r\"]); st.std_r = float(js[\"std_r\"])\n",
    "        return st\n",
    "\n",
    "STATS = Stats(); STATS.fit(S, R, Sp)\n",
    "(Path(ROOT/\"data\"/\"stats.json\")).write_text(json.dumps(STATS.dumps(), indent=2))\n",
    "print(\"Stats guardadas:\", (ROOT/\"data\"/\"stats.json\").resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86422048-10c2-4c6e-bda6-9748424f3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# 4) MDN-RNN: RNN que predice una mezcla Gaussiana sobre\n",
    "#    Δs, además de recompensa y done. Entrenamos con NLL.\n",
    "# ======================================================\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- utilidades MDN\n",
    "def mdn_params(x, K, D):\n",
    "    \"\"\"\n",
    "    Parte la salida lineal en:\n",
    "    - pi_logits: [B,T,K]\n",
    "    - mu:        [B,T,K,D]\n",
    "    - log_sigma: [B,T,K,D]\n",
    "    \"\"\"\n",
    "    B,T,_ = x.shape\n",
    "    pi = x[...,:K]\n",
    "    mu = x[...,K:K+K*D].view(B,T,K,D)\n",
    "    ls = x[...,K+K*D:].view(B,T,K,D)\n",
    "    return pi, mu, ls\n",
    "\n",
    "def mdn_nll(x, pi_logits, mu, log_sigma):\n",
    "    \"\"\"\n",
    "    NLL de una mezcla Gaussiana diagonal.\n",
    "    x: [B,T,D], pi_logits: [B,T,K], mu/log_sigma: [B,T,K,D]\n",
    "    \"\"\"\n",
    "    import math as _m\n",
    "    B,T,D = x.shape; K = pi_logits.shape[-1]\n",
    "    x = x.unsqueeze(2)             # [B,T,1,D]\n",
    "    var = torch.exp(2*log_sigma)   # [B,T,K,D]\n",
    "    log_comp = -0.5*((x-mu)**2/var + 2*log_sigma + _m.log(2*_m.pi))  # [B,T,K,D]\n",
    "    log_comp = log_comp.sum(-1)    # [B,T,K]\n",
    "    log_mix  = torch.log_softmax(pi_logits, -1) + log_comp\n",
    "    nll = -torch.logsumexp(log_mix, -1)  # [B,T]\n",
    "    return nll.mean()\n",
    "\n",
    "# --- dataset de secuencias (teacher forcing)\n",
    "class SeqDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Corta el flujo plano en bloques de longitud T.\n",
    "    Devuelve:\n",
    "      x  = concat( s_normalizado, onehot(a) )  --> entrada al RNN\n",
    "      ds = Δs_normalizado                      --> target para MDN\n",
    "      r  = r_normalizado\n",
    "      d  = done (0/1)\n",
    "    \"\"\"\n",
    "    def __init__(self, S, A, R, Sp, D, stats:Stats, T=32):\n",
    "        DS = Sp - S\n",
    "        self.s  = ((S  - stats.mu_s)/stats.std_s).astype(np.float32)\n",
    "        self.ds = ((DS - stats.mu_ds)/stats.std_ds).astype(np.float32)\n",
    "        self.r  = ((R  - stats.mu_r)/stats.std_r).astype(np.float32)\n",
    "        self.d  = D.astype(np.float32)\n",
    "        self.a  = A.astype(np.int64)\n",
    "        self.T  = T\n",
    "        self.N  = len(S)//T\n",
    "    def __len__(self): return self.N\n",
    "    def __getitem__(self, i):\n",
    "        i0 = i*self.T; i1 = i0 + self.T\n",
    "        s   = torch.from_numpy(self.s[i0:i1])     # [T,8]\n",
    "        ds  = torch.from_numpy(self.ds[i0:i1])    # [T,8]\n",
    "        r   = torch.from_numpy(self.r[i0:i1])     # [T]\n",
    "        d   = torch.from_numpy(self.d[i0:i1])     # [T]\n",
    "        a   = torch.from_numpy(self.a[i0:i1])     # [T]\n",
    "        aoh = F.one_hot(a, num_classes=4).float() # [T,4]\n",
    "        x   = torch.cat([s, aoh], -1)             # [T,12]\n",
    "        return x, ds, r, d\n",
    "\n",
    "# --- el RNN con cabezas MDN + r + done\n",
    "class MDNRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM(256) → MDN (K mezclas) para Δs, y cabezas para r (MSE) y done (BCE).\n",
    "    \"\"\"\n",
    "    def __init__(self, s_dim=8, a_dim=4, h=256, K=5):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(input_size=s_dim+a_dim, hidden_size=h, batch_first=True)\n",
    "        self.mdn = nn.Linear(h, K + K*s_dim + K*s_dim)  # pi + mu + log_sigma\n",
    "        self.head_r = nn.Linear(h, 1)\n",
    "        self.head_d = nn.Linear(h, 1)\n",
    "        self.K = K; self.s_dim = s_dim\n",
    "    def forward(self, x, h=None):\n",
    "        y, h = self.rnn(x, h)           # y: [B,T,H]\n",
    "        mdn_out = self.mdn(y)\n",
    "        pi, mu, ls = mdn_params(mdn_out, self.K, self.s_dim)\n",
    "        r = self.head_r(y).squeeze(-1)\n",
    "        d = torch.sigmoid(self.head_d(y)).squeeze(-1)\n",
    "        return (pi, mu, ls), r, d, h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b586a87-a811-43ad-8f0c-a281e036a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 01 | tr(MDN:-2.121 r:1.000 d:0.251) | va(MDN:-7.393 r:0.947 d:0.129)\n",
      "Ep 02 | tr(MDN:-7.398 r:0.995 d:0.129) | va(MDN:-8.707 r:0.946 d:0.125)\n",
      "Ep 03 | tr(MDN:-8.070 r:0.993 d:0.124) | va(MDN:-9.459 r:0.945 d:0.121)\n",
      "Ep 04 | tr(MDN:-8.010 r:0.993 d:0.121) | va(MDN:-6.933 r:0.944 d:0.117)\n",
      "Ep 05 | tr(MDN:-9.250 r:0.992 d:0.117) | va(MDN:-9.894 r:0.944 d:0.114)\n",
      "Ep 06 | tr(MDN:-9.615 r:0.991 d:0.114) | va(MDN:-9.799 r:0.943 d:0.110)\n",
      "Ep 07 | tr(MDN:-8.227 r:0.990 d:0.110) | va(MDN:-9.143 r:0.941 d:0.107)\n",
      "Ep 08 | tr(MDN:-9.153 r:0.988 d:0.107) | va(MDN:-9.919 r:0.938 d:0.104)\n",
      "Ep 09 | tr(MDN:-11.653 r:0.987 d:0.105) | va(MDN:-12.689 r:0.937 d:0.101)\n",
      "Ep 10 | tr(MDN:-10.985 r:0.984 d:0.103) | va(MDN:-8.548 r:0.936 d:0.100)\n",
      "Ep 11 | tr(MDN:-9.446 r:0.983 d:0.101) | va(MDN:-10.549 r:0.934 d:0.098)\n",
      "Ep 12 | tr(MDN:-11.449 r:0.980 d:0.099) | va(MDN:-12.619 r:0.931 d:0.096)\n",
      "Ep 13 | tr(MDN:-12.082 r:0.979 d:0.097) | va(MDN:-8.556 r:0.929 d:0.094)\n",
      "Ep 14 | tr(MDN:-11.434 r:0.977 d:0.095) | va(MDN:-12.028 r:0.927 d:0.092)\n",
      "Ep 15 | tr(MDN:-10.999 r:0.974 d:0.093) | va(MDN:-11.436 r:0.925 d:0.090)\n",
      "Ep 16 | tr(MDN:-10.076 r:0.971 d:0.092) | va(MDN:-10.004 r:0.921 d:0.088)\n",
      "Ep 17 | tr(MDN:-11.834 r:0.967 d:0.090) | va(MDN:-13.179 r:0.918 d:0.087)\n",
      "Ep 18 | tr(MDN:-12.419 r:0.964 d:0.089) | va(MDN:-13.504 r:0.914 d:0.086)\n",
      "Ep 19 | tr(MDN:-10.105 r:0.961 d:0.088) | va(MDN:-11.532 r:0.909 d:0.085)\n",
      "Ep 20 | tr(MDN:-11.818 r:0.955 d:0.086) | va(MDN:-13.395 r:0.904 d:0.083)\n",
      "Guardado MDN-RNN en: /home/jovyan/MVP_RL_LunarLander/world_models/checkpoints/mdnrnn.pt\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# 5) Entrenador: DataLoader, NLL + MSE + BCE, guardado\n",
    "# ======================================================\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "def train_mdnrnn(S, A, R, Sp, D, stats:Stats,\n",
    "                 K=5, H=256, T=32, batch=512, lr=3e-4, epochs=25):\n",
    "    ds = SeqDataset(S,A,R,Sp,D, stats, T=T)\n",
    "    n = len(ds); n_val = max(256, n//10); n_tr = n - n_val\n",
    "    tr_set, val_set = random_split(ds, [n_tr, n_val], generator=torch.Generator().manual_seed(SEED))\n",
    "    tr = DataLoader(tr_set, batch_size=batch, shuffle=True,  drop_last=True)\n",
    "    va = DataLoader(val_set, batch_size=batch, shuffle=False, drop_last=False)\n",
    "\n",
    "    model = MDNRNN(K=K, h=H)  # CPU va sobrado para este tamaño\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    best_loss = 1e9; best_state=None\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train(); tr_mdn=tr_r=tr_d=0; nsteps=0\n",
    "        for x, ds_t, r_t, d_t in tr:\n",
    "            (pi,mu,ls), rp, dp, _ = model(x)\n",
    "            loss_mdn = mdn_nll(ds_t, pi, mu, ls)\n",
    "            loss_r   = F.mse_loss(rp, r_t)\n",
    "            loss_d   = F.binary_cross_entropy(dp, d_t)\n",
    "            loss = loss_mdn + loss_r + loss_d\n",
    "            opt.zero_grad(); loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            tr_mdn += loss_mdn.item(); tr_r += loss_r.item(); tr_d += loss_d.item(); nsteps += 1\n",
    "\n",
    "        model.eval(); va_mdn=va_r=va_d=0; m=0\n",
    "        with torch.no_grad():\n",
    "            for x, ds_t, r_t, d_t in va:\n",
    "                (pi,mu,ls), rp, dp, _ = model(x)\n",
    "                va_mdn += mdn_nll(ds_t, pi, mu, ls).item()\n",
    "                va_r   += F.mse_loss(rp, r_t).item()\n",
    "                va_d   += F.binary_cross_entropy(dp, d_t).item()\n",
    "                m += 1\n",
    "\n",
    "        train_log = f\"Ep {ep:02d} | tr(MDN:{tr_mdn/nsteps:.3f} r:{tr_r/nsteps:.3f} d:{tr_d/nsteps:.3f})\"\n",
    "        val_log   = f\" | va(MDN:{va_mdn/m:.3f} r:{va_r/m:.3f} d:{va_d/m:.3f})\"\n",
    "        print(train_log + val_log)\n",
    "\n",
    "        score = va_mdn/m + va_r/m + va_d/m\n",
    "        if score < best_loss:\n",
    "            best_loss = score\n",
    "            best_state = {k:v.cpu() for k,v in model.state_dict().items()}\n",
    "\n",
    "    # Guardamos el mejor\n",
    "    torch.save(best_state, ROOT/\"checkpoints\"/\"mdnrnn.pt\")\n",
    "    (ROOT/\"checkpoints\"/\"stats.json\").write_text(json.dumps(stats.dumps(), indent=2))\n",
    "    print(\"Guardado MDN-RNN en:\", (ROOT/\"checkpoints\"/\"mdnrnn.pt\").resolve())\n",
    "    return model\n",
    "\n",
    "MDN = train_mdnrnn(S,A,R,Sp,D, STATS, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b687d2e-6760-4dbb-a220-7d53d61b290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 6) DreamEnv: simula episodios en el “sueño”\n",
    "# ==========================================\n",
    "class DreamEnv:\n",
    "    \"\"\"\n",
    "    Simulador ligero:\n",
    "      - Estado interno = (s_t real, h_t del LSTM)\n",
    "      - step(a) usa el MDN para muestrear Δs con temperatura tau\n",
    "      - devuelve (s_{t+1}, r_hat, done_hat)\n",
    "    \"\"\"\n",
    "    def __init__(self, mdn:MDNRNN, stats:Stats, tau=1.15, device=\"cpu\"):\n",
    "        self.net = mdn.eval().to(device)\n",
    "        self.stats = stats; self.tau = tau; self.device = device\n",
    "        self.h = None; self.s = None\n",
    "\n",
    "    def reset(self, s0=None):\n",
    "        if s0 is None:\n",
    "            s0 = np.array([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0., 0.], np.float32)\n",
    "        self.s = clip_obs(s0); self.h = None\n",
    "        return self.s.copy()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, a:int):\n",
    "        # normalizamos s_t y concatenamos onehot(a)\n",
    "        s_n = (torch.tensor(self.s, dtype=torch.float32, device=self.device)\n",
    "               - torch.tensor(self.stats.mu_s, device=self.device)) / torch.tensor(self.stats.std_s, device=self.device)\n",
    "        a_oh = F.one_hot(torch.tensor([a], device=self.device), num_classes=4).float()\n",
    "        x = torch.cat([s_n.unsqueeze(0), a_oh], -1).unsqueeze(0)  # [1,1,12]\n",
    "\n",
    "        (pi,mu,ls), r_n, d_p, self.h = self.net(x, self.h)\n",
    "\n",
    "        # muestreo de mezcla con temperatura\n",
    "        pi = torch.softmax(pi[0,0]/self.tau, -1)  # [K]\n",
    "        k  = torch.multinomial(pi, 1).item()\n",
    "        mu_k  = mu[0,0,k]\n",
    "        std_k = torch.exp(ls[0,0,k]) * self.tau\n",
    "        ds_n  = torch.normal(mu_k, std_k)\n",
    "\n",
    "        # desnormalizamos y avanzamos\n",
    "        ds = (ds_n.cpu().numpy())*self.stats.std_ds + self.stats.mu_ds\n",
    "        sp = clip_obs(self.s + ds)\n",
    "        r  = float((r_n[0,0].item())*self.stats.std_r + self.stats.mu_r)\n",
    "        d  = bool(d_p[0,0].item() > 0.5)\n",
    "        self.s = sp\n",
    "        return sp, r, d, {\"k\":k, \"pi\":pi.cpu().numpy()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d63df6a-ffa7-4b08-9113-58353fc069a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 7) Render minimalista (triángulo) + guardado de videos\n",
    "# ==========================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "import imageio\n",
    "\n",
    "def draw_lander_from_state(s, size=256):\n",
    "    \"\"\"\n",
    "    Dibuja un triángulo representando la nave usando x,y y el ángulo theta.\n",
    "    Es muy barato y suficiente para visualizar el “sueño”.\n",
    "    \"\"\"\n",
    "    x,y, vx,vy, theta, vth, leg_l, leg_r = s\n",
    "    fig = plt.figure(figsize=(size/100, size/100), dpi=100)\n",
    "    ax = fig.add_axes([0,0,1,1]); ax.set_xlim(-1.5,1.5); ax.set_ylim(-0.2,1.6); ax.axis('off')\n",
    "    ax.plot([-1.5,1.5],[0,0], lw=2, color='gray')  # suelo\n",
    "\n",
    "    L = 0.1\n",
    "    pts = np.array([[0,L],[-L,-L],[L,-L]])\n",
    "    c, sct = math.cos(theta), math.sin(theta)\n",
    "    R = np.array([[c,-sct],[sct,c]])\n",
    "    pts = (pts @ R.T) + np.array([x,y])\n",
    "    ax.add_patch(Polygon(pts, closed=True, color='steelblue'))\n",
    "\n",
    "    canvas = FigureCanvasAgg(fig); canvas.draw()\n",
    "    frame = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)\n",
    "    frame = frame.reshape((int(fig.bbox.height), int(fig.bbox.width), 4))[...,:3]\n",
    "    plt.close(fig)\n",
    "    return frame\n",
    "\n",
    "def save_video(frames, path, fps=30):\n",
    "    path = Path(path); path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    imageio.mimsave(path, frames, fps=fps)\n",
    "    return str(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73bcbc9-8896-428b-be02-c905cdbcebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128_w,256)-aCMA-ES (mu_w=66.9,w_1=3%) in dimension 21380 (seed=124935, Wed Aug 13 14:08:06 2025)\n",
      "Gen 001 | best_dream_return=-760.0\n",
      "Gen 002 | best_dream_return=-716.5\n",
      "Gen 003 | best_dream_return=-664.8\n",
      "Gen 004 | best_dream_return=-664.8\n",
      "Gen 005 | best_dream_return=-664.8\n",
      "Gen 006 | best_dream_return=-526.7\n",
      "Gen 007 | best_dream_return=-526.7\n",
      "Gen 008 | best_dream_return=-526.7\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 8) Controller pequeño + CMA-ES (entrenado en DreamEnv)\n",
    "# ==========================================================\n",
    "import cma\n",
    "import torch.nn as nn\n",
    "\n",
    "class Controller(nn.Module):\n",
    "    \"\"\"\n",
    "    Política muy compacta.\n",
    "    - Entrada = concat(s_t, h_t) ≈ 8 + 256 = 264 dim\n",
    "    - Salida = logits para 4 acciones (softmax → distribución)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=8+256, hidden=64, out_dim=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.Tanh(),\n",
    "            nn.Linear(hidden, hidden), nn.Tanh(),\n",
    "            nn.Linear(hidden, out_dim)\n",
    "        )\n",
    "    def forward(self, s, h):\n",
    "        # h es una tupla (h_n, c_n); aplanamos h_n\n",
    "        h_flat = (h[0] if h is not None else torch.zeros(1,1,256)).squeeze(0).squeeze(0)\n",
    "        x = torch.cat([torch.tensor(s, dtype=torch.float32), h_flat.cpu()], -1)\n",
    "        logits = self.net(x)\n",
    "        return torch.softmax(logits, -1).detach().cpu().numpy()\n",
    "\n",
    "def flatten_params(model:nn.Module):\n",
    "    with torch.no_grad(): return torch.cat([p.view(-1) for p in model.parameters()]).numpy()\n",
    "\n",
    "def assign_params(model:nn.Module, vec):\n",
    "    vec = torch.tensor(vec, dtype=torch.float32)\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for p in model.parameters():\n",
    "            n = p.numel()\n",
    "            p.copy_(vec[i:i+n].view_as(p)); i += n\n",
    "\n",
    "def dream_episode(env:DreamEnv, ctrl:Controller, max_steps=1000, render_every=0):\n",
    "    frames=[]; s = env.reset(); total=0.0\n",
    "    for t in range(max_steps):\n",
    "        if render_every and (t%render_every==0): frames.append(draw_lander_from_state(s,256))\n",
    "        probs = ctrl(s, env.h)\n",
    "        a = int(np.random.choice(4, p=probs))\n",
    "        s, r, d, _ = env.step(a); total += r\n",
    "        if d: break\n",
    "    return total, frames\n",
    "\n",
    "def train_cma_dream(mdn_path=ROOT/\"checkpoints\"/\"mdnrnn.pt\",\n",
    "                    stats_path=ROOT/\"checkpoints\"/\"stats.json\",\n",
    "                    gens=60, popsize=384, episodes_per_ind=8, tau=1.15):\n",
    "    \"\"\"\n",
    "    CMA-ES entrena el controlador EXCLUSIVAMENTE en el entorno soñado.\n",
    "    - gens: generaciones de evolución\n",
    "    - popsize: tamaño de población por generación\n",
    "    - episodes_per_ind: episodios soñados por individuo (promediamos)\n",
    "    - tau: temperatura del MDN (1.1–1.3 suele ir bien)\n",
    "    \"\"\"\n",
    "    mdn = MDNRNN(); mdn.load_state_dict(torch.load(mdn_path, map_location=\"cpu\"))\n",
    "    stats = Stats.loads(json.loads(Path(stats_path).read_text()))\n",
    "    dream = DreamEnv(mdn, stats, tau=tau, device=\"cpu\")\n",
    "\n",
    "    ctrl = Controller()\n",
    "    x0 = flatten_params(ctrl)\n",
    "    es = cma.CMAEvolutionStrategy(x0, 0.5, {\"popsize\": popsize, \"maxiter\": gens, \"verb_log\":0, \"verb_disp\":1})\n",
    "\n",
    "    best = (None, -1e9)\n",
    "    gen = 0\n",
    "    while not es.stop():\n",
    "        cand = es.ask()\n",
    "        fitness = []\n",
    "        for w in cand:\n",
    "            assign_params(ctrl, w)\n",
    "            returns = []\n",
    "            for _ in range(episodes_per_ind):\n",
    "                ret, _ = dream_episode(dream, ctrl, max_steps=1000, render_every=0)\n",
    "                returns.append(ret)\n",
    "            mean_ret = float(np.mean(returns))\n",
    "            fitness.append(-mean_ret)  # CMA minimiza\n",
    "            if mean_ret > best[1]:\n",
    "                best = (w.copy(), mean_ret)\n",
    "        es.tell(cand, fitness)\n",
    "        gen += 1\n",
    "        print(f\"Gen {gen:03d} | best_dream_return={best[1]:.1f}\")\n",
    "\n",
    "    assign_params(ctrl, best[0])\n",
    "    torch.save(ctrl.state_dict(), ROOT/\"checkpoints\"/\"controller.pt\")\n",
    "    print(\"Controller guardado:\", (ROOT/\"checkpoints\"/\"controller.pt\").resolve())\n",
    "\n",
    "    # Grabamos un video soñado como muestra\n",
    "    _, frames = dream_episode(dream, ctrl, max_steps=800, render_every=2)\n",
    "    save_video(frames, ROOT/\"videos\"/\"dream_controller.mp4\", fps=30)\n",
    "    print(\"Video soñado →\", (ROOT/\"videos\"/\"dream_controller.mp4\").resolve())\n",
    "    return ctrl\n",
    "\n",
    "CTRL = train_cma_dream(gens=40, popsize=256, episodes_per_ind=6, tau=1.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a97cb-22e1-44e5-8a50-7077cc325b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 9) Eval real/soñado + videos + RMSE de rollouts del modelo\n",
    "# ==========================================================\n",
    "def eval_real_with_ctrl(env_id=ENV_ID, ctrl:Controller,\n",
    "                        mdn_path=ROOT/\"checkpoints\"/\"mdnrnn.pt\",\n",
    "                        stats_path=ROOT/\"checkpoints\"/\"stats.json\",\n",
    "                        episodes=10, grab_first=True):\n",
    "    \"\"\"\n",
    "    Ejecuta el controller en el entorno REAL.\n",
    "    Importante: actualizamos h_t del MDN usando (s_t, a_{t-1}) reales\n",
    "    para que el controller reciba su memoria como en el paper.\n",
    "    \"\"\"\n",
    "    mdn = MDNRNN(); mdn.load_state_dict(torch.load(mdn_path, map_location=\"cpu\")); mdn.eval()\n",
    "    st  = Stats.loads(json.loads(Path(stats_path).read_text()))\n",
    "    env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "    scores=[]; frames=[]\n",
    "\n",
    "    for ep in range(episodes):\n",
    "        s,_ = env.reset(seed=SEED+ep); s = clip_obs(s)\n",
    "        total=0.0; done=False; h=None; a_prev=0\n",
    "        while not done:\n",
    "            # Paso del RNN con (s_t, a_{t-1}) reales para actualizar h\n",
    "            s_n = (torch.tensor(s, dtype=torch.float32) - torch.tensor(st.mu_s)) / torch.tensor(st.std_s)\n",
    "            a_oh = F.one_hot(torch.tensor([a_prev]), num_classes=4).float()\n",
    "            x = torch.cat([s_n.unsqueeze(0), a_oh], -1).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                _,_,_, h = mdn(x, h)\n",
    "\n",
    "            probs = ctrl(s, h)\n",
    "            a = int(np.random.choice(4, p=probs))\n",
    "            sp, r, term, trunc, _ = env.step(a); d = term or trunc\n",
    "            if grab_first and ep==0:\n",
    "                frames.append(env.render())\n",
    "            total += r; s = clip_obs(sp); done=d; a_prev=a\n",
    "        scores.append(total)\n",
    "\n",
    "    env.close()\n",
    "    if grab_first and frames:\n",
    "        save_video(frames, ROOT/\"videos\"/\"real_controller.mp4\", fps=30)\n",
    "        print(\"Video REAL →\", (ROOT/\"videos\"/\"real_controller.mp4\").resolve())\n",
    "    return float(np.mean(scores)), scores\n",
    "\n",
    "def rollout_rmse(model:MDNRNN, stats:Stats, S,A,Sp, horizon=30, trials=300):\n",
    "    \"\"\"\n",
    "    Mide qué tan bien “se sostiene” el modelo por múltiples pasos.\n",
    "    Tomamos fragmentos del dataset y comparamos (x,y,theta).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    idx = np.random.choice(len(S)-horizon-1, size=min(trials, len(S)-horizon-1), replace=False)\n",
    "    errs=[]\n",
    "    with torch.no_grad():\n",
    "        for i in idx:\n",
    "            s = S[i]; h=None\n",
    "            err=[]\n",
    "            for t in range(horizon):\n",
    "                a = A[i+t]\n",
    "                s_n = (torch.tensor(s, dtype=torch.float32) - torch.tensor(stats.mu_s)) / torch.tensor(stats.std_s)\n",
    "                a_oh = F.one_hot(torch.tensor([a]), num_classes=4).float()\n",
    "                x = torch.cat([s_n.unsqueeze(0), a_oh], -1).unsqueeze(0)\n",
    "                (pi,mu,ls),_,_, h = model(x, h)\n",
    "                k = torch.softmax(pi[0,0],-1).argmax().item()  # “mejor” componente\n",
    "                ds_n = mu[0,0,k]\n",
    "                ds = (ds_n.numpy())*stats.std_ds + stats.mu_ds\n",
    "                s = clip_obs(s + ds)\n",
    "                err.append(np.square(s[:3] - Sp[i+t][:3]).mean())  # x,y,theta\n",
    "            errs.append(np.mean(err))\n",
    "    return float(np.sqrt(np.mean(errs)))\n",
    "\n",
    "# --- Cargar mejor controller y evaluar\n",
    "CTRL.load_state_dict(torch.load(ROOT/\"checkpoints\"/\"controller.pt\", map_location=\"cpu\"))\n",
    "\n",
    "# 9a) Retorno soñado (un episodio + vídeo ya guardado)\n",
    "dream = DreamEnv(MDN, STATS, tau=1.15, device=\"cpu\")\n",
    "dream_ret, _ = dream_episode(dream, CTRL, max_steps=800, render_every=0)\n",
    "print(f\"Return SOÑADO (1 ep): {dream_ret:.1f}\")\n",
    "\n",
    "# 9b) Retorno real (10 episodios + vídeo del 1º episodio)\n",
    "real_mean, real_scores = eval_real_with_ctrl(ENV_ID, CTRL, episodes=10, grab_first=True)\n",
    "print(f\"Return REAL (media 10 eps): {real_mean:.1f}\")\n",
    "\n",
    "# 9c) Calidad del modelo: RMSE de rollout a 30 pasos\n",
    "rmse30 = rollout_rmse(MDN, STATS, S,A,Sp, horizon=30, trials=300)\n",
    "print(f\"RMSE@30 pasos (x,y,theta): {rmse30:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff4d19-7818-4db7-bd9b-1b629741781d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22616a-d382-44de-a594-680df4f1314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pipreqs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598205ec-79f2-48b7-a671-d07e8dba3cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
